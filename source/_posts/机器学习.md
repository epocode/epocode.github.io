---
title: 机器学习笔记
tags: 
  - 机器学习
  - 学习笔记
categories:
  - 人工智能
abbrlink: 15279
date: 2025-07-15 16:30:00
---

# 数据

## 数据的获取

常用的数据集

- MNIST:手写的数据集
- ImageNet：从搜索引擎爬取的图片数据集
- AudioSet：Youtube上的声音切片，用于声音的分类
- Kinetics：Youtube上的视频切片，用于人类行为的分类
- KITTI：交通工具的传感器收集到的数据
- Amazon Review：亚马逊用户评论的数据集
- SQuAD：维基百科的问题答案对数据集
- LibriSpeech：1000小时的有声读物，用于声音识别

如何找数据集：

- Paperswithcodes Datasets
- Kaggle DataSets
- Google Dataset search
- Open Data on AWS

 数据融合：将多个数据源融合成一个数据集（类似于数据库中，不同表join成一个表）

 数据增强

人工合成数据

# 机器学习的分类

- 监督学习：数据是有标签的
  - 回归：预测连续的值
  - 分类：预测的值是离散的
- 非监督学习：数据是没有标签的
- 半监督学习
- 强化学习

# 机器学习开源库scikit-learn

## 基本使用

- 线性回归

```python
#导入库
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.preprocessing import StandardScaler#特征缩放为z-score标准化


scaler = StandardScaler()
X_norm = scaler.fit_transform(X_train)
sgdr = SGDRegressor(max_iter=1000)
sgdr.fit(X_norm, y_train)

b = linear_model.intercept_
w = linear_model.coef_
```

- 逻辑回归

  ```python
  from sklearn.linear_model import LogisticRegression
  
  X = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])
  y = np.array([0, 0, 0, 1, 1, 1])
  
  lr_model = LogisticRegression()
  lr_model.fit(X, y)
  y_pred = lr_model.predict(X)//预测
  print("Accuracy on training set:", lr_model.score(X, y))//计算模型的准确率
  ```



## 实现推荐系统（协同过滤算法）


- 这里描述的是一个电影推荐系统，左边为电影列表，右边为用户和电影对应的特征（电影的类型）。中间是用户的打分，最右边是电影的特征值（与该类的相关程度）
- 协同过滤算法：根据其他和你评分相近的用户给你推荐商品

### 代价函数

- 跟线性回归一样，单个用户的代价函数为：
  <!-- $$
  J(w^{(i)},b^{(j)}) = \frac{1}{2m^{(j)}}\sum_{i:r(i,j)=1}(w^{(j)}.x^{(i)}+b^{(j)}-y^{(i,j)})^2+\frac{\lambda}{2m^{(j)}}\sum_{k=1}^n(w_k^{j})^2 \\
  w^{(j)}为用户对应的参数,x^{(i)}是第i部电影的特征向量\\
  r(i,j)为1表示用户j给电影i打分了，没打分为0.\\
  y^{(i,j)}是用户j给电影i的打分\\
  m^{(j)}表示用户j打分的电影的数量
  $$ -->

- 学习用户参数时，整个用户群体的代价函数为：
  $$
  J(w^{(1)},...,w^{(n_u)},b^{(1)},...,b^{(n_u)})=\frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}(w^{(j)}.x^{(i)}+b^{(j)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^n(w_k^{j})^2\\
  n_u为用户的数量
  $$
  
- 

$$
J(x^{(1)},x^{(2)},...,x^(n_m))=\frac{1}{2}\sum_{j=1}^{n_m}\sum_{j:r(i,j)=1}(w^{(j)}.x^{(i)}+b^{(j)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_m}\sum_{k=1}^n(x_k^{(i)})^2\\
这时候用户的参数是已知的
$$

- 将上面两个代价函数加在一起，就是求x、w、b的代价函数：
  $$
  J(W,b,x)=\frac{1}{2}\sum_{(i,j):r(i,j)=1}(w^{(j)}.x^{(i)}+b^{(j)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^n(w_k^{j})^2+\frac{\lambda}{2}\sum_{j=1}^{n_m}\sum_{k=1}^n(x_k^{(i)})^2\\
  $$
  
- 这就是协同过滤算法（从多个用户那里收集数据，来预测未来其他用户的评分），使用梯度下降来优化w,x和b

### 二值标签

标签的含义：

- 1：表示系统已经推荐给了该用户，并且该用户已经接受该推荐
- 0：表示已经推荐，用户没有采取下一步的行动，或者拒绝
- ？：表示还未推送

$f_{(w,b,x)}(x)=g(w^{(j)}.x^{(i)}+b^{(i)})$

损失函数为：$L(f_{(w,b,x)}(x),y^{(i,j)})=-y^{(i,j)}log(f_{(w,b,x)}(x))-(1-y^{(i,j)})log(1-f_{(w,b,x)}(x))$

代价函数为：$J(w,b,x)=\sum_{(i,j):r(i,j)=1}L(f_{(w,b,x)},y^{(i,j)})$

### 找到相似的商品

计算商品特征向量的距离，越近越相似。

## 基于内容的过滤方法

- 匹配用户特征和商品特征给用户推荐商品



- $$
  x_u^{(j)}是用户自身的特征向量，x_m^{(i)}是电影自身的特征向量。这两者特征的数量可以不同\\
  v_u^{(j)}是转化后用户的新特征向量，v_m^{(i)}是转化后的电影的新 特征向量。两者特征的数量必须相同\\
  用这两个新的特征向量替换w^{(j)}.x^{(i)}，从而实现预测用户对电影的评分。
  $$

### 使用神经网络进行特征的转换



### 代码实现


# 监督学习 

## 回归

### 线性回归

- 模型:$f_(\vec{w},b) = \vec{w}.\vec{x} + b$

- python实现向量化:这样的好处是可以通过并行计算提高运行效率

  ```python
  np.array([])#创建向量
  np.dot(v1, v2)#两个向量的点乘
  v1 - v2 #两个向量相减
  a.v1 #表示向量乘以一个值
  ```

### 代价函数

- 损失函数：$$\frac{1}{2}(f_{\mathbf{w},b}(\mathbf{x}^{(i)}) - y^{(i)})^2 \tag{3}$$

- 代价函数：$$J(\mathbf{w},b) = \frac{1}{2m} \sum\limits_{i = 0}^{m-1} (f_{\mathbf{w},b}(\mathbf{x}^{(i)}) - y^{(i)})^2 \tag{3}$$ 

### 梯度下降

- 梯度下降公式:$x^i$ 表示第i个样本，$x_j$表示第j个参数。
  $$
  w_1 = w_1 - \alpha\frac{1}{m}\sum_{i = 1}^m(f_{\vec{w}, b}(x^i) - y^i)x_1^i \\
  ...
  w_n = w_n - \alpha\frac{1}{m}\sum_{i = 1}^m(f_{\vec{w}, b}(x^i) - y^i)x_n^i \\
  b = b - \alpha\frac{1}{m}\sum_{i = 1}^m(f_{\vec{w}, b}(x^i) - y^i)
  $$


### 特征缩放

- 当训练集中每个特征的取值范围相差较大的时候，可能导致梯度下降的时间边长，因此将不同特征的取值范围缩放到一定可比较的范围内，可以提高训练的效率。
- 实现的方法：
  - $\mu_j = \frac{1}{m}\sum_{i=0}^{m-1}x_j^{(i)}$
  - $\sigma_j^2=\frac{1}{m}\sum_{i=0}^{m-1}(x_j^i-\mu_j)^2$
  - 除以特征取值范围的最大值，如`[20, 200]`，缩放后的范围为`0.1, 1`
  - 均值归一化：如$x_1$的取值范围为$[a, b]$，$x_1$的均值为$\mu_1$,则缩放后的范围为$[\frac{a - \mu_1}{b - a}, \frac{b - \mu_1}{b - a}]$
  - z-score标准化：$x_1的取值范围为 [a, b],均值为\mu_1,标准差为\sigma_1,那么z-score标准化后的范围为[\frac{a-\mu_1}{\sigma_1}, \frac{b-\mu_1}{\sigma_1}]$ 
- 注意：在使用特征缩放后求得的模型，在预测的时候也要使用对应数据的特征缩放值。

### 收敛的判断

- 学习曲线：横坐标为迭代的次数，纵坐标为当前代价$J$ 
- 收敛的判断：当两次迭代之间的$J$小于某个很小的值的时候，表示已经收敛。 

### 学习率的选择

1. 首先选择一个很小的学习率$\alpha$，然后迭代少量的次数，用于判断该代码是否正确运行
2. 然后逐渐提高学习率的值

### 特征工程

特征工程是将原始数据转化成更好的表达问题本质的特征的过程，使得将这些特征运用到预测模型中能提高对不可见数据的模型预测精度。

### 多项式回归（包含了非线性）

- 做法：把多项式转化成多元线性的式子，通过对特征进行特征缩放
- 例子：
  1. $y=w_0x+w_1x^2+b$为要求的多项式
  2. 将原先的$x$转化成$x 和x^2$这两个特征
  3. 然后通过多元线性回归的方式求出对应的w和b。
  4. 注意转化成多个特征后，一般特征的取值差别较大， 应该再次使用特征缩放加快迭代的速度。

## 分类

### 二分类

- 任务：预测的结果是离散的有限的值
- 算法：逻辑回归

#### 逻辑回归

- 逻辑函数(logistic function)、sigmoid函数:$g(z) = \frac{1}{1 + e^{-z}}， 0<g(z)<1$，

- 函数图像：


- 逻辑回归模型：$f_{\vec{w},b}(\vec{x})=g(z)=g(\vec{w}.\vec{x}+b)=\frac{1}{1+e^{-(\vec{w}.\vec{x}+b)}}$

- 模型的含义：$对于一个给定的x，预测值为等于1的概率$

#### 决策边界

$$
设置当g(z)>=0.5时，预测结果为1,其余为0\\
因此由逻辑函数可知，当z>=0时预测结果为1\\
我们称z=\vec{w}.\vec{x}+b=0这个条线为决策边界\\
其中z不一定为线性的，可以为任意的多项式 
$$

#### 代价函数

- 使用平方误差代价函数的图像（不适用）：


- 逻辑回归的单个样本的损失函数：
  $$
  L(f_{\vec{w},b}(\vec{x}^{(i)}),y^{(i)})=\begin{cases}
  -log(f_{\vec{w},b}(\vec{x}^{(i)})) && y^{(i)}=1\\
  -log(1-f_{\vec{w},b}(\vec{x}^{(i)}))&&y^{(i)}=0
  \end{cases}
  $$

- 整体的代价函数：$J(\vec{w},b)=\frac{1}{m}\sum_{i=1}^{m}L(f_{\vec{w},b}(\vec{x}^{(i)}),y^{(i)})$

- 简化后的损失函数：$L(f_{\vec{w},b}(\vec{x}^{(i)}),y^{(i)})=-y^{(i)}log(f_{\vec{w},b}(\vec{x}^{(i)}))-(1-y^{(i)})log(1-f_{\vec{w},b}(\vec{x}^{(i)}))$

- 简化后的代价函数也可以推导出:$L(f_{\vec{w},b}(\vec{x}^{(i)}),y^{(i)})=-\frac{1}{m}\sum_{i=1}^{m}[y^{(i)}log(f_{\vec{w},b}(\vec{x}^{(i)}))+(1-y^{(i)})log(1-f_{\vec{w},b}(\vec{x}^{(i)}))]$

#### 梯度下降

$$
w_1 = w_1 - \alpha\frac{1}{m}\sum_{i = 1}^m(f_{\vec{w}, b}(x^i) - y^i)x_1^i \\
...
w_n = w_n - \alpha\frac{1}{m}\sum_{i = 1}^m(f_{\vec{w}, b}(x^i) - y^i)x_n^i \\
b = b - \alpha\frac{1}{m}\sum_{i = 1}^m(f_{\vec{w}, b}(x^i) - y^i)
$$

- 梯度下降的算法跟线性回归一样，不同的是里面的$f_{w,b}(x)$函数的实现不同

### 多分类（softmat回归）

- 用于多分类

- 计算方法：
  $$
  \begin{aligned}
  z_i &= w_ix+b_i \\
  a_i &= \frac{e^{z_i}}{\sum_{i=1}^{n}e^{z_i}}
  \end{aligned}
  $$

- 损失函数：


- tensorflow实现多分类:

  ```python
  model = Sequential([
      Dense(units=25,activation='relu'),
      Dense(units=15,activation='relu'),
      Dense(units=10,activation='linear')
  ])
  model.compile(loss=SparseCrossEntropy(from_logits=True))
  model.fit(X, Y, epochs=100)
  logit = model(X)
  f_x = tf.nn.sigmoid(logit)
  ```

### 多标签分类

- 例子：判断一张图片中是否有汽车，行人，红绿灯。给定一张图片的输入，输出是一个(1, 3)的列表，列表的三个值分别表示是否有汽车、行人、红绿灯。这相当于是将三个二分类问题合在了一起


## 决策树

### 分类树

- 定义：分类树属于二叉树，每个内部节点表示特征，叶节点表示最终的分类结果，用于处理二分类问题。
- 决策树要解决的问题是：
  - 每个内部节点应该放什么特征
  - 到什么时候结束判断
- 熵函数：$H(p_)=-p_1log_2(p_1)-(1-p_1)log_2(1-p_1)$.其中$p_1$指的是二分类中某个类别数量占总数的比例。熵的作用是判断一组数据的不纯度，熵越高数据越不纯。

#### 信息增益

- 定义：


  - $p_1为每个节点上某个类所占比例$。
  - $w为当前类占总类中的比例。$
  - $w^{left}H(p_1^{left}+w^{right}H(p_1^{right}))$.求的是当前分类后的加权平均熵
  - 用父节点的熵值减去子节点的加权平均熵，得到信息增益 

- 信息增益的作用：其一是作为衡量分类特征的效益，其次是判断增益是否足够小，从而停止分类，避免过拟合。

#### 特征的选择

- 选择不同特征下的信息信息增益最大的那个特征

#### 终止分类的标准

- 当前节点的信息熵为0
- 深度达到了阈值
- 信息增益小于阈值
- 节点中样本数量小于阈值

#### 特征有多个离散值的解决方案（hot-one编码）

- 当一个特征有m个取值的时候，我们将这个特征用m个二进制特征替换

#### 特征值为连续值的解决方案

- 对该特征取不同的阈值，计算不同阈值下的信息增益，将信息增益最大的那个阈值作为该特征阈值。

### 回归树

- 用于回归问题的树模型
- 最终的预测值是每个叶节点上样本输出的加权平均值

#### 特征的选择


- 跟分类树相同，计算出父节点样本的方差和两个子节点样本的方差的加权平均，计算信息增益，取增益最大特征为该节点的特征。

### 集成学习

- 其中包含很多决策树，最终预测值由不同的决策树的输出共同决定

#### 放回抽样

- 在所有样本中选择训练样本，若要选择m个训练样本，那么每次从整体样本中随机选择一个然后放回，再随机选择一个，直到选完m个。

#### 随机森林算法

- 按照放回抽样的方式选择m个训练样本，然后训练出一颗决策树。重复该过程训练多个决策树。重复的次数应该在66到100左右，过大影响性能，收益不高。
- 每次训练的时候，假设有总共n个特征，每次从这n个特征中选取k个特征进行决策树的训练
- 策树进行投票。

#### XGBoost

- 实现过于复杂，一般使用其开源库来实现这个算法

# 无监督学习

## K-均值聚类算法

具体的步骤：

- 随机选择两个簇质心
- 遍历每一个点，判断该点与哪一个簇质心更接近，将其归于更近的那个簇质心
- 对于每一类点，计算他们的均值，将簇质心移动到均值这个位置。
- 重复以上过程，不断移动簇质心
- 如果两次计算之间的簇质点基本不移动了，表示算法已经收敛了

符号意义：

- $c^{(i)}表示第i个样本被分配到的簇质点的编号$
- $\mu_k表示第k个簇质点的位置$
- $\mu_{c^{(i)}}表示第i个样本所属的簇质点的位置$

### 代价函数

- 该代价函数又被称为畸变函数

$$
J(c^{(1)},...,c^{(m)},\mu_1,...,\mu_{m})=\frac{1}{m}\sum_{i=1}^{m}||x^{(i)}-\mu_{c^{(i)}}||^2
$$

- $第二范式的计算：||(x_1,y_1)-(x_2,y_2)||=\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$
- 最小化的过程：
  - 为每一个样本归类的时候，是通过改变$c^{(i)}$来降低代价函数
  - 当计算每类样本的均值的时候，是通过改变$\mu_i$来降低代价函数

### 初始簇质点的选择

- 簇质点的数量为k，要保证$k<m$。m为训练样本的数量，当簇质点数量大于等于训练样本数量的时候，将没有意义。
- 从训练样本中随机选择k个样本，将这k个样本作为簇质点
- 随机初始化的情况不同，得到的结果也不同，可能会陷入局部最优解
- 解决办法：多次初始化（50~100），选择代价最小的那一组簇质点
- 簇的数量选择：
  - 随着簇数量的增加，损失函数也会相应减小：
  - 自己根据情况选择

## 异常检测算法

- 通过观察正常事件的数据集，学会检测异常或者在异常事件发生时发出危险信号

### 高斯分布（正态分布）

$$
p(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)^2}{2\sigma^2}} \\
\sigma是标准差，\mu是均值\\
\mu=\frac{1}{m}\sum_{i=1}^mx^{(i)}\\
\sigma^2=\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu)^2
$$

### 具体算法

$$
假设某个样本x有n个特征，分别为x_1,x_2,...,x_n\\
p(x)=\prod_{j=1}^np(x_j;\mu_j,\sigma_j^2)\\
因为每个特征都是独立分布的，因此概率密度函数相乘为同时发生的概率
$$

过程：

- 选择样本合适的n个特征
- 拟合所有样本的特征
- 计算测试样本对应的概率
- 判断该概率是否低于某个阈值$\epsilon$，低于则为异常

### 模型评估

- 训练集中的样本全是非异常的样本
- 交叉验证集 中的样本有少量是异常标记的样本
- 然后判断该$\epsilon $下的模型在交叉验证集上的精度

### 异常检测和监督学习的比较

- 当负样本（非异常样本）数量很多，正样本数量很少的时候，用异常检测算法，这时候负样本用来训练模型，正样本用来进行模型调优
- 当正样本数量和负样本数量都很多的时候使用监督学习
- 监督学习中的正负样本都很多，因此预测的结果应该是以前出现过的，而对于以前没有出现过的类型，监督学习的预测结果就不够好。而异常检测算法的正样本数量很少，而负样本很多，因此预测的结果很大概率将不是以前出现过的类别。比如想找到以前没有出现过的缺陷，最好使用异常检测算法。如果想发现以前已经出现过的缺陷，那么最好使用监督学习算法。

### 特征的选择

- 相比监督学习，异常检测算法的特征选择更加重要

特征选择的方法：

- 特征的分布要是高斯分布。
- 如果不是高斯分布，那么就对该特征的取值进行处理，让结果满足高斯分布。比如$特征x转化成新的特征log(x+c)$，不断调整c的值来让分布更加接近高斯分布
- 如果在交叉验证集验证的时候，发现异常的样本的概率也很高的话，那么就进行误差分析（分析出错的原因）。试着给模型添加新的特征，来纠正模型，让模型发现这些异常。



# 强化学习

- 基本要素：状态、奖励、行动
- 奖励：每个状态能够获得的值
- 折扣因子：一个百分比，每多走一步，折扣因子就会加一次幂。每个状态获得的奖励要乘以这个折扣因子。
- 回报：从当前状态到终止状态能够获得的奖励。每走一步都要乘以折扣因子的i次方。

- 策略函数：将状态s作为输入，将这个状态映射到某个动作a

## 状态动作价值函数

- $Q(s,a)$：Q函数表示在某个状态执行某一个行动后，然后按照策略$\Pi(s)$一直运行，直到终止状态，返回最终的回报
- 某个状态下的最佳动作是能够返回最大$Q(s,a)$的那个动作 

## 贝尔曼方程

$$
Q(s,a)=R(s)+\gamma maxQ(s',a')\\
s'为下一个状态，a'为下一个状态执行的动作。\\
R(s)是当前状态能获得的奖励，\gamma是折扣因子
$$

但是强化学习过程不一定会按照我们要求的来进行，可能会出现一些随机的动作，这是我们无法预期的。因此我们要做的是随机执行很多次这个过程，找到期望回报最大的那个策略。因此修改后的方程为$Q(s,a)=R(s)+\gamma E(maxQ(s',a')),E(...)表示未来期望的平均回报$

## 学习价值状态函数

1. 将所有的状态和动作作为神经网络的输入

2. 输出的是Q(s,a)

3. 神经网络的输入X为s和a，输出y为Q(s,a)

4. 随机化神经网络中的参数

5. 创建训练集：

   1. 创建元组$(s^{(i)},a^{(i)},R(s^{(i)},s'^{(i)}),s^{(i)}为随机选择的一个状态，a^{(i)}也是随机选择的一个动作。R()是奖励函数，表示当前的操作可以获得的奖励。s'^{(i)}表示下一个动作$

   2. 这样随机创建n个元组

   3. 然后从这n个元组中获取训练集

   4. $$
      元组中的(s^{(i)},a^{(i)})作为神经网络的输入X，输出Y=R(s^{(i)})+\gamma \mathop{max}\limits_{a'}Q(s'^{(i)},a'^{(i)})\\
      这里的Q(s,a)就可以通过神经网络计算得到
      $$

6. 训练







# 优化算法

## 梯度下降

## Adam

- 介绍：在梯度下降的基础上，自动调整学习率，并且模型每个参数的学习率都不一样。



# 模型评估

## 样本的分类（训练集和交叉验证集）

- 将数据集分成训练集和测试集（一般3/7分），然后对于不同的模型，计算在测试集上的误差（判断该模型泛化的能力），选择误差最小的模型。
- 将数据集分成三部分：训练集、交叉验证集、测试集。用训练集训练一系列模型，用交叉验证集找到损失最小的模型，最后用测试集测试该模型的性能

## 过拟合和欠拟合

- 当前模型特征太多（如增加了特征的高次项），导致对训练样本拟合得太好，而对于非训练样本的其他样本，预测结果很差，这种情况就是过拟合。
- 当前模型特征太少，导致训练样本都拟合得很差，这种情况为欠拟合。

过拟合的解决办法：

- 增加训练样本
- 尝试减少特征数量，靠直觉选出最合适的特征子集
- 利用正则化减小某些特征参数的大小

## 正则化

- 通过添加某些项，来达到减小某些特征参数的效果，具体含义是通过添加对应的特征项来惩罚这些特征，从而尽量避免过拟合
- 但是一开始不知道哪些项需要正则化，因此对多有的特征项进行惩罚。

### 解决线性回归

- **正则线性回归**的代价函数为:$J_{\vec{w},b}=\frac{1}{2m}\sum_{i=1}^m(f_{\vec{w},b}(\vec{x}^{(i)})-y^{(i)})+\frac{\lambda}{2m}\sum_{j=1}^nw_j^2$

- $\frac{\partial}{\partial w_j}J(\vec{w},b) =\frac{1}{m}\sum_{i = 1}^m(f_{\vec{w}, b}(x^{(i)} - y^{(i)})x_j^{(i)}+\frac{\lambda}{m}w_j$

- $\frac{\partial}{\partial b}J(\vec{w},b)=\frac{1}{m}\sum_{i = 1}^m(f_{\vec{w}, b}(x^i) - y^i)$



  新增加的这一项是在原来的迭代的基础上继续减少特征参数的值。因此能够通过调整$\lambda$的值来减小特征参数。

### 解决逻辑回归的问题

- 逻辑回归的代价函数：$L(f_{\vec{w},b}(\vec{x}^{(i)}),y^{(i)})=-\frac{1}{m}\sum_{i=1}^{m}[y^{(i)}log(f_{\vec{w},b}(\vec{x}^{(i)}))+(1-y^{(i)})log(1-f_{\vec{w},b}(\vec{x}^{(i)}))]+\frac{\lambda}{2m}\sum_{j=1}^{n}w_j^2$

## 方差和偏差

- 高偏差：训练集误差很大
- 高方差：交叉验证集的误差远大于训练集上的误差

## 正则化参数对偏差和方差的影响



- $\lambda 过大，模型会尽可能将参数进行压缩，因此最后导致模型偏差过大$
- $\lambda 过小，导致模型对训练集过拟合，方差过大$



- 因此选择模型的过程就是找到最合适的正则化参数

## 建立性能基准

- 建立性能基准是因为数据集中的数据总带有噪音，因此需要一个标准来判断模型的性能

- 当训练集误差跟基准差距较大则为高偏差
- 当交叉验证集误差跟训练集误差差距较大则为高方差

## 学习曲线

- 学习曲线就是通过画出不同**训练集大小**时训练集和交叉验证的**准确率**，可以看到模型在新数据上的表现，进而来判断模型是否方差偏高或偏差过高，以及增大训练集是否可以减小过拟合。

- 欠拟合的情况：

 

  当训练集的规模变大，误差也不会减小

- 高方差的情况


  提高训练样本的数量，可以减小误差

## 高误差的处理方式

- 增大训练集的大小：减小高方差
- 减小特征集的大小：减小高方差
- 增加特征数量：减小高偏差
- 增加多项式特征：减小高偏差
- 减小$\lambda$:减小高偏差
- 增大$\lambda$：减小高方差
