---
title: 深度学习笔记
tags: 
  - 深度学习
  - 学习笔记
categories:
  - 人工智能
abbrlink: 6
---
#  基础知识

- 线性回归：有显式解（表示可以利用所有数据一次性计算出最优的参数）
- softmax分类：

## 损失函数

- L2  Loss:$l(y, y^{\prime})=\frac{1}{2}(y-y^{\prime})^2$

- L1 Loss:$l(y, y^{\prime})=|y-y^{\prime}| $



## 优化算法

### 指数加权平均

- 定义一个系数$\beta$，$某个数据v_t 表示为 \beta v_{t-1} + (1-\beta)\theta_t$
- $每个计算后的值表示前\frac{1}{1 - \beta}个数据的平均值$
- 用这个代替普通的平均值的计算，更加简单，并且容易实现
- 偏差矫正：当t较小的时候，得到的指数加权平均值不符合预期，需要进行修正：
  - $令校正系数为1 - \beta^t, 其中\beta^t是指\beta的t次方$
  - $然后令得到的v_t 除以该系数，从而得到最终的v_t$
  - 当t很大的时候，该系数接近于1，那么偏差矫正的效果将消失，因此偏差矫正作用的地方是初始的数据

### 小批量梯度下降

- 相比于批量梯度下降使用整个训练集进行训练，小批量随机梯度下降每次只处理小批量的样例
- 对于每一个batch，算出了损失函数，然后反向传播更新参数，接着训练下一个batch。
- 每一轮为一个epoch

### 动量梯度下降（Gradient Descent with Momentum)

- 计算过程
  - 每次更新参数的时候：使用$v_{dw}和v_{db}来替换dw和db$
  - $v_{dw}=\beta v_{dw} + (1-\beta)dw$，$db$计算同理
  - 上个公式中的$v_{dw}$表示上一次$dw$的指数加权平均值。
- 该优化算法可以加快梯度下降的速率

### RMSprop （Root Mean Square prop）均方根传递

- 计算过程
  - $S_{dw}=\beta S_{dw} +(1-\beta)dw^2, S_{db} = \beta S_{db}+(1-\beta)db^2$
  - $w=w-\alpha \frac{dw}{\sqrt{S_{dw}} + \epsilon}, b = b - \alpha \frac{db}{\sqrt{S_{db}} + \epsilon}$
- 作用：让参数在震荡方向上的幅度变小

### Adam算法

- 该算法是结合了Momentum和RMSprop的产物
- 计算过程：
  - $设置 V_{dw}=V_{db}=S_{dw}=S_{db}=0$
  - $V_{dw}=\beta_1V_{dw}+(1-\beta_1)dw, V_{db}=\beta_1V_{db}+(1-\beta_1)db$
  - $S_{dw}=\beta_2 S_{dw} +(1-\beta_2)dw^2, S_{db} = \beta_2 S_{db}+(1-\beta_2)db^2$
  - $V_{dw}^{corrected}=V_{dw}/(1-\beta_1^t), V_{db}^{corrected}=V_{db}/(1-\beta_1^t)$
  - $S_{dw}^{corrected}=S_{dw}/(1-\beta_1^t), S_{db}^{corrected}=S_{db}/(1-\beta_1^t),修正初始的数据$
  - $w=w-\alpha\frac{V_{dw}^{corrcted}}{\sqrt{S_{dw}^{corrected}}+\epsilon}, b=b-\alpha\frac{V_{db}^{corrcted}}{\sqrt{S_{db}^{corrected}}+\epsilon}$，$\epsilon是为了避免分母为0$
- 参数的选择：
  - $\alpha 手动调整$
  - $\beta_1 为0.9$
  - $\beta_2 为0.999$
  - $\epsilon 为10^{-8}$

## 激活函数

**为什么要使用激活函数：避免神经网络层的塌陷。**

- sigmoid函数：sigmoid函数作为隐藏层的激活函数的时候，梯度下降的速率过慢，因此不使用sigmoid函数作为隐藏层的激活函数。
- ReLU函数

![image-20231101144639152](http://imgage-storage.oss-cn-chengdu.aliyuncs.com/img/image-20231101144639152.png)

- leaky ReLU: $a = max(0.01z, z)$

- softmax激活函数

- **因此经验隐藏层的激活函数建议使用ReLU函数

## 数据集

- 数据集划分成训练集，验证集和测试集
- 训练集：用来训练模型参数
- 验证集：用来调整超参数
- 测试集：只能用一次，用来评估模型的精度
- k-折交叉验证：将数据集划分成k块，每次去其中一块作为验证集，其余作为训练集。将每一次求得的验证集的误差求平均得到最终误差。（在数据集不够大的时候做这样的操作）

## 避免过拟合

### 权重衰退（正则化）

- 通过$\lambda$限制参数的取值范围，从而减少模型的复杂度，减少过拟合的概率。
- $l_{final} = l(w, b) + \frac{\lambda}{2}||w||_2^2,||x||_2表示l2范式$，这里在原有的损失函数的基础上加上了一个参数的l2范式，表示当参数取值过大的时候，就给模型一个惩罚，拉回参数防止参数过大。

### 丢弃法 

- 设置一个概率keep_prob表示保留该输出的概率，对于某些层，处理完输出后，对每个输出除以keep_prob。
- dropout只能用在训练中，推理的时候不能使用，防止输出结果不唯一。
- 常用在多层感知机的隐藏层上面

### 其他

- 扩增数据集
- early stopping

## 反向传播

- 神经网络通过反向传播计算出每个代价函数对每个参数的导数，从而进一步更新参数，避免了手动计算导数。

反向传播的具体步骤：

1. **前向传播（Forward Pass）**：在前向传播过程中，输入数据经过神经网络，每一层都执行一系列的线性变换和激活函数操作，最终得到预测结果。这个过程中，每个神经元的输出和中间变量都被保存，以便后续计算导数。

2. **计算损失（Loss Calculation）**：在前向传播后，计算模型的损失，这通常是一个表示预测结果与实际目标的差距的函数。

3. **反向传播（Backward Pass）**：反向传播是关键步骤。它从损失开始，通过链式法则，逆序计算导数。具体步骤如下：

   a. 计算损失对于网络输出的梯度，这是链式法则的起点。

   b. 从输出层向输入层反向传播，计算每一层的参数（权重和偏差）对于损失的梯度。这包括计算激活函数的导数。

   c. 更新每一层的参数，以使损失最小化。这是通过使用梯度下降或其他优化算法来实现的。

4. **重复迭代**：上述步骤反复迭代，直到损失足够小或达到其他训练停止条件。

- 神经网络分为三层：输入层($输入X的结构为(n, m)。m为样本数量，n为特征数量$)、隐藏层、输出层
- 神经网络的理解：
  - 将输入层的一些特征转化为隐藏层的新的特征，用这些新的特征去预测结果值，相当于是神经网络自动学习特征，代替了手动的特征工程。
  - 神经元的理解：每一层的神经元对应一个特征。$每个神经元的结构为(1, m)，相当于该神经元表示每个样本在该特征下的值$
  - 输出a的理解：神经网路向前传播的过程中,每层的输出A的结构为(k, m)，其中k的数量一直在变化，但是m的数量不变。因此输出的每一列表示每个样本对应的输出，直到最后也是对应样本的结果值。
  - 对参数W的理解：W结构为(k, n)，其中n为前一层神经元的数量，k为后一层神经元的数量。而神经元的数量又可以表示为特征的 数量，因此向前传播的过程中是不断改变每一层输入的参数的特征数量，即不断改变(n, m)中的n，但是不改变m
- 激活函数：由前一层的神经元计算得到下一层的神经元。该函数为sigmoid函数。
- 计算的过程：$a_{j}^{[l]}=g(\vec{w_{j}^{[l]}}.\vec{x}^{[l-1]}+b^{[l]})(a为计算得到的激活值,下标j表示第几个神经元，上标[l]表示第l层)。$
- 构建神经网络，要做的工作是：决定有几个隐藏层，以及每个隐藏层有几个神经元。
- 符号表示：
  - $X$: 输入值
  - $n^{[l]}$：表示l层的神经元的数量
  - $W^{[l]}$: l层的参数
  - $b^{[l]}$
- 参数的结构：
  - $W^{[l]}为(n^{[l]}, n^{[l-1]})$
  - $b^{[l]}为(n^{[l]},1)$

## 模型的调优

### 加快训练速度

#### 选择合适的batch大小

- 当训练样本较小的时候（2000)，使用批量梯度下降
  - 当训练样本较大的时候，选择64到512作为batch的大小

#### 参数的初始化

- 参数合理初始化的意义：加快迭代的速率

- 为什么W不能初始化为0：当所有参数设置为一样的时候，那么每个神经元做的工作将会一样，我们希望的是不同的神经元做不同的任务。因此参数初始化的时候应该随机初始化。

- 为什么参数不能初始化过大：当参数设置得过大时，那么z很大的概率就很大，那么在sigmoid激活函数上的梯度下降将会变得很慢。因此参数一般设置得很小
- He initialization：一种初始化参数的方法，在原来随机初始化的基础上乘上$\sqrt{\frac{2}{上一层的神经元的数量}}$

#### 归一化处理

- 作用加快梯度下降的速率
- 对输入做归一化，$令X = \frac{X}{\sigma},\sigma 为所有输入的均方差$

#### 学习率衰减

- 设置学习率随着训练的轮次不断减小，加快最初的训练速度
- 有很多不同的学习率衰减方式

### 梯度检验

- 检验反向传播的代码是否正确
- 具体做法
  - 由反向传播函数得到对应的$dw, db$
  - 设置$w^+ = w + \delta, w^- = w - \delta, b+ = b^+ \delta, b^-=b-\delta$
  - 然后将这些参数代入向前传播的 函数中，计算出对应的损失值$J^+,J^-$
  - 计算$dw^{\prime}=\frac{J^+-J^-}{2\delta}$
  - 对比$dw^{\prime}和dw$,相差不大则反向传播的代码正确，否则反向传播的代码中有问题。


### 超参数的设置

- 参数：模型能够自动迭代计算出来的值
- 超参数：需要手动设置的值
  - 学习率
  - 迭代次数
  - 隐藏层的数量
  - 每个隐藏层的神经元的数量
  - 激活函数
  - batch size
  - 正则化系数

**超参数的选择**：

- 随机取样
- 但是随机取样的时候不能在超参数的取值范围内线性取随机值，而是利用非线性的方式。 

# 构建机器学习系统

## 正交化

- 在机器学习中，正交化指的是，通过对模型的一些方面进行考虑，调整某些参数，能够提高模型的精确率。而且这些参数是互不影响的

## 单一量化评估指标

- 当评估一个算法的时候，有多个评估指标，比如精确率和召回率，那么不同算法的衡量将考虑多个方面，不利于算法的优化，因此将这多个指标通过某种形式转化成单一的量化指标，比如精确率和 召回率通过调和平均转化成F1来评价算法的准确率。
- 这样做的作用是，优化模型的过程中提高决策效率

## 满足指标和优化指标

- 满足指标：只要达到某个要求就行
- 优化指标：要尽可能的让某个指标越大或者越小
- 策略：选择一个指标作为优化指标，其余指标作为满足指标。在达到满足指标的条件下，选择优化指标更好的那一种

## dev set 和 test set

### 分布

- 交叉验证集的数据应该和测试集应该有相同的分布，比如亚洲的数据和美洲的数据就是分布不同的数据，用某一个分布的数据训练的模型不满足在另一个分布的数据的测试。因此要将所有不同分布的数据进行打乱，然后交叉验证集和测试集分别从这个打乱后的数据中取值。

### 大小

- 在深度学习下，数据量已经很大了，因此传统的70/30的分解模式已经不再适用，而是尽可能增大训练集的比例，比如98%，剩下的留给交叉验证集和测试集（当确信自己的数据足够大，不会产生偏差，甚至可以丢弃测试集，在交叉验证集上进行迭代）

## 人类级别的表现

- 定义：人类水平的表现，根据不同的要求，人类级别的表现将为不同的值。比如医学图像的诊断，不同类型的医生将有不同的误差值。要根据目标选择合适的人类级别的表现。
- 当算法表现超过人类级别的表现后，机器学习算法 的表现将提升得越来越慢，最终也超不过一个界限（贝叶斯最优误差）。当机器学习表现超过人类表现的时候，就很难判断优化哪方面的问题，提升算法性能也就变慢了
- 当有一项人类做得比较好的任务的时候，那么就可以将人类的误差作为贝叶斯误差。通过比较训练误差与贝叶斯误差判断偏差问题，用训练误差和开发集误差判断方差问题。然后判断专注于解决偏差问题还是方差问题。
  - 但是在绝大多数的任务上如非自然感知的任务，机器学习已经做得比人类较好了。

## 误差分析

- 人工手动分析预测错误的样本，并决定下一步是否要在降低该错误率上下功夫

## 错误标签问题

- 介绍：有的时候，在所给的训练集上，有的标签是错误的，那么是否有必要去修正这些标签则成为一个问题。
- 当训练集上的标签错误是随机造成的，而不是有一定规律产生的错误，那么就没与必要去修正这些错误，机器学习算法依然能够正常工作
- 如果是开发集上出现的错误标签，那么在误差分析的时候记录由错误标签引起的错误识别数量占所有的错误识别数量的比例，如果比例较大，那么有必要去纠正这些错误的标签，否则没必要。

## 样本分布问题

- 问题介绍：当由两批不同分布的样例，想要测试的是较小的那一批样例，但是占比较大的那批样例跟目标样例的 分布不相同，因此如何将这些样本分配到训练集/开发集/测试集则成为一个问题
- 不应该将两批样本混合在一起随机分配到三个集合中，因为在开发集中，想要的那部分样例占极少部分，那么训练出来的模型将不符合我们的预期
- 解决方案：将所有的非目标样本放到训练集中，将目标样本分成三部分分别放入这三个集合中。

## 训练集和开发集分布不同的问题

- 问题介绍：当训练集和开发集的分布不同的时候，在开发集上的误差可能很大，如何判断该误差是由分布不同引起的还是由方差引起的则成了一个问题。
- 解决方案：在训练集上随机选出一个**train-dev训练-开发集**，这个集合与训练集的分布一致，剩下的训练集样本作为新的训练集。然后计算三个集合上的误差，如果训练开发集误差和开发集误差仍然很大，那么原来存在着方差问题。如果训练开发集的误差较小，而开发集的误差较大，那么则是分布一致引起的误差。如果是第二种情况，那么该问题被称作**失配问题（mismatch problem）**。
- 失配问题的解决方案：进行误差分析，判断开发集和训练集的不同之处在哪里，然后通过合成数据来增加更多跟开发集分布相同的样本，减少分布不同带来的误差。

## 多任务学习

- 多任务学习：他的输出有多个维度，e.g.一张图片中检测几种事物是否存在，那么输出Y的每个维度表示对应的事物是否在图片中出现,那么Y的结构为$(n, m)其中n为要检测的事物，m为样例$
- 使用多任务学习的条件：
  - 这些不同任务共享低级特征
  - 其他任务的样本数量合远大于单个任务的样本数量

## 端到端学习

- 将分成几个阶段的学习过程直接合并成一个输入到输出的任务
- 端到端学习的条件：
  - 有大量的数据

# 卷积神经网络

## 卷积层

符号解释：

- $输入：n_h \times n_w$
- $核：k_h\times k_w$
- padding:$p_w, p_h，这里的p_w是填充到矩阵某一边的数量，不是两边总共的数量$
- stride:$s_w, s_h$
- $输出：(n_h+2*p_h-k_h+s_h)/s_h\times (n_w+2*p_w-k_w+s_w)/s_w$
- $二维卷积：y_{i,j}=\sum_{a=1}^{h}\sum_{b=1}^w w_{-a,-b}x_{i+a, j+b}$

### 边缘检测

- 通过卷积和计算出原来图像的一些边缘，这些卷积核也被叫做过滤器，通过不同的过滤器得到不同的分界线。

-  过滤器：一个3*3的矩阵，用来找出图像中的分界线：

  - $$
    \begin{bmatrix}
    1&0&-1\\1&0&-1\\1&0&-1
    \end{bmatrix}这是一个竖向的边界检测器
    $$

- 但是在深度学习中，不用手动设定，而是将这个卷积核作为一个参数，在反向传播的过程中进行训练。然后得到一个优良的边界检测器。

### padding（填充）

- 卷积过程中的问题：
  - 每次卷积后的图像将会变小
  - 卷积过程中国，边缘的数据的利用率太低，导致边缘上的特征无法被考虑到
- padding通过在图像的边缘填充，来解决上面的问题。
- 分类：
  - valid 卷积：没有填充的卷积
  - same 卷积：通过设置填充的大小，让卷积后的矩阵跟原矩阵大小一致。因此要设置padding(不是一边，是总的数量)的大小为$kernel大小 - 1$


### stride（步幅）

- 卷积过程中，每次要跳过的数量
- $\lfloor这个符号表示向下取整\rfloor$
- 步幅通常设置为1，当计算量过大的时候才不设置这个值为1

### channel（通道数)

- $channel_{in}表示输入的通道的数量，channel_{out}表示输出的通道的数量（也表示卷积核的数量）。$
- 符号表示：
  - $c_i表示输入的通道数，c_o表示输出的通道数$
  - 输入尺寸:$c_i\times n_h \times n_w$
  - 核尺寸：$c_o \times c_i \times k_h \times k_w$
  - 输入出：$c_o \times m_h \times m_w$


## 池化层

- 作用：因为卷积层对位置的变化太敏感了，最大池化层可以减小微小偏差带来的影响。
  - 计算过程跟卷积一样，给一个池化的核，去卷输入。但是不同于卷积层，池化层的channel输入和输出是一样的。

- 池化层只要确定了超参数（池化核大小、stride、padding),就没有参数需要学习了。
- 分类：包括最大池化层、平均池化层

## 批量归一化层

- 该算法用在全连接层和卷积层的输出后面，激活函数的前面（批量归一化是线性变换）。也可以作用于全连接层的卷积层的输入上面。
  - 对于全连接层的，是作用在特征维度上面的，比如：$m*n的矩阵，m为样本数量，n为特征数量。那么归一化是对每一列进行批量归一化$
  - 对于卷积层，是作用在通道维度上面的。

- $对于每一个输出的Z^{[l]},计算出Z的均值\mu_{\beta}，然后计算出方差\sigma_{\beta}^2$
- $令Z=\frac{X-\mu_{\beta}}{\sqrt{\sigma_{\beta}^2}+\epsilon}$
- $最后通过\gamma和\beta实现伸缩和平移,即Z=\gamma Z+\beta$，为了保证归一化后的数据合理，通过引入$\gamma$方差和$\beta $均值来调整归一化后的数据分布。这两个参数是可以学习的。

## 深度卷积神经网络

### LeNet

![image-20231101194712011](http://imgage-storage.oss-cn-chengdu.aliyuncs.com/img/image-20231101194712011.png)

### AlexNet

![image-20231103192843704](http://imgage-storage.oss-cn-chengdu.aliyuncs.com/img/image-20231103192843704.png)

- 在LeNet的基础上更加复杂 

### VGG

![image-20231103192917667](http://imgage-storage.oss-cn-chengdu.aliyuncs.com/img/image-20231103192917667.png)

-  使用可重复的卷积块来构建深度卷积神经网络

### GoogLeNet

- 加入了Reception块

### ResNet

- ResNet的思想是增加更多更复杂的层的时候，模型不会变差

- 解释：
  $$
  假设y=f(x)+g(f(x)),前面一个是简单的网络，后面一个是在这个简单的网络的基础上添加了更复杂的网络\\
  y^{\prime}=f^{\prime}(x) + g^{\prime}(f(x))。由于链式法则，反向传播的时候，复杂的网络对应的梯度小于简单网络的梯度，当复杂网络的梯度过小的时候，\\就会忽略这个梯度，避免出现梯度消失的现象。
  $$
  

# 序列模型

- 模型：
  - 马尔科夫假设：模型使用前$\tau$个数据预测当前的值
  - 因变量自回归模型：用一个$h$变量来总结前面的值，然后根据这个总结值来预测新的预测值

## 符号解释

$$
x^{<t>(i)}，表示第i个样本中，t表示时间序列。其中输入x是通过建立一个词与数值的字典来转换的。x不是数值，而是通过one-hot编转化成的一个数组。\\
y^{<t>(i)}，对应的输出，输出为一个值，比如在查找句子中的人名的时候，为人名输出1反之输出0\\
n_x表示每个样本中单元的个数\\
a^i表示每个rnn单元传递给下一个单元的值\\
w_{aa}和w_{ya}为乘以a_i的系数\\
w_{ax}和w_{yx}为乘以x_i的系数\\
b_a为偏置
$$

## 向前传播

$$
a^t=g_a(w_{aa}a_{t-1}+w_{ax}x_t+b_a)这里的激活函数一般使用tanh\\
y^t=g_y(w_{ya}a_{t}+b_y)这个激活函数一般使用sigmoid
$$

## 

- 词嵌入：词的表示方法有很多，前面介绍的是热独编码。这里用词嵌入来表示词。不同于之前给定一个字典，每个词通过热独编码转化成一个向量。这里是特征化表示法来表示每个词，即用许多特征来描述一个词。这样做的好处是让一些词之间有了联系（比如苹果和梨子），提高了算法的泛化能力。它把一个维数为所有词的数量的高维空间嵌入到一个维数低得多的连续向量空间中。
- 嵌入矩阵： 每个词仍然用热独编码构建一个唯一的向量（m, 1）与之对应，其中m为字典的大小。嵌入矩阵的大小为(n, m)，n为每个词的特征数量，m为字典大小。用嵌入矩阵乘词对应的编码向量，得到这个词对应的特征向量（n, 1)。

- 词嵌入算法：用来训练嵌入矩阵的

- 常用模型：encoder-decoder.

 ## GRU门控循环单元

![image-20231120110115891](http://imgage-storage.oss-cn-chengdu.aliyuncs.com/img/image-20231120110115891.png)



# 计算机视觉

## 数据增广

- 通过对训练集的图片进行缩放、裁剪、变色等处理提升训练集的数量，降低模型过拟合的概率。

## 微调（迁移学习的一种方法）

- 将已经训练好的神经网络模型参数运用到新问题的解决上
- 具体做法：将原有的神经网络模型中的最后一层换成目标问题所需要的新网络层，初始化这新创建的一层，保留其它层的参数。当新问题的样本数较少的时候，只用训练最后一层的参数。如果样本数量较大，则可以训练整个网络的参数。
- 这里使用原有的参数作为神经网络的参数叫做**预训练**，训练新的参数叫做**微调**。 
- 迁移学习的要求：被迁移的模型数据要足够多，新任务的数据量较少

## 目标检测

- 任务：检测图片中是否有要检测的目标，并指定目标的位置。
- 输出:$[P_c, bx, by, bh, bw, C_1, C_2, C_3]^T$.
- 解释：$P_c为检测到目标的预测概率，bx,by,bh,bw用来确定目标的位置，C_1,C_2,C_3表示具体是哪一个目标$

### 锚框

- 以每个像素为中心，生成多个缩放比和宽高比（aspect ratio）不同的边界框。 这些边界框被称为**锚框**

### yolo算法

## 语义分割

- 任务：给定一个图像，对图片上的每一个像素进行分类
- 

### 转置卷积（transpose convolution)

- 将一个小尺寸的输入转化成一个更大尺寸的输出

## 人脸识别

### 学习similarity function

- 输入两张图片，输出它们之间的相似程度

### Siamese network(孪生网络)



![image-20231101155004595](http://imgage-storage.oss-cn-chengdu.aliyuncs.com/img/image-20231101155004595.png)

- 训练一个这样的神经网络，图片为输入，输出的是一个一维的向量
- 当两张相同图片输入的时候，要保证输出的向量之间的差距较小$||f(x^{(i)})-f(x^{(j)})||^2$
- 如果图片不同，那么输出的向量之差就要越大。

损失函数：

- $参数定义：A为当前图片，P为同一个人的其他图片，N为其他人的图片,\alpha为相同图片差异值与不同图片差异值的差$
- $损失函数L(A,P,N)=max(||f(A)-f(P)||^2-||f(A)-f(N)||^2+\alpha,0)$

## 风格转移  
